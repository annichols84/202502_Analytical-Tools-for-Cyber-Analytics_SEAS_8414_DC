{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# SEAS 8414_DC8 – Assignment 8: Cognitive SOAR Implementation\n",
        "# Author: Anetta Nichols\n",
        "# Date: 22 August 2025\n",
        "# Environment: Google Colab with Miniconda (Python 3.10)\n",
        "# Purpose: Full pipeline for synthetic threat actor simulation, model training, and Streamlit-based attribution interface."
      ],
      "metadata": {
        "id": "g0kfRrJLDVzh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLSijRpzxjxR",
        "outputId": "847acb36-3cf5-4c1f-a442-8fc323b43113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-23 03:51:43--  https://repo.anaconda.com/miniconda/Miniconda3-py310_24.1.2-0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 134948792 (129M) [application/octet-stream]\n",
            "Saving to: ‘miniconda.sh’\n",
            "\n",
            "miniconda.sh        100%[===================>] 128.70M   141MB/s    in 0.9s    \n",
            "\n",
            "2025-08-23 03:51:44 (141 MB/s) - ‘miniconda.sh’ saved [134948792/134948792]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "                                                                                 \n",
            "Installing base environment...\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\bdone\n",
            "Executing transaction: | \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Python 3.10.13\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download and install Miniconda with Python 3.10\n",
        "!wget -O miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-py310_24.1.2-0-Linux-x86_64.sh\n",
        "!chmod +x miniconda.sh\n",
        "!bash ./miniconda.sh -b -f -p /usr/local\n",
        "\n",
        "# Step 2: Update environment variables so Python 3.10 packages are accessible\n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.10/site-packages\")\n",
        "\n",
        "# Step 3: Confirm Python 3.10 is installed\n",
        "!/usr/local/bin/python3.10 --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Install PyCaret (latest stable version)\n",
        "!/usr/local/bin/python3.10 -m pip install pycaret"
      ],
      "metadata": {
        "id": "1yXbxBld3vzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Write the full script to train_model.py\n",
        "train_model_code = \"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pycaret.classification import ClassificationExperiment\n",
        "from pycaret.clustering import ClusteringExperiment\n",
        "\n",
        "def generate_synthetic_data(num_samples=600):\n",
        "    print(\"Generating synthetic dataset...\")\n",
        "\n",
        "    profiles = {\n",
        "        'state_sponsored': {\n",
        "            'having_IP_Address': [1, -1], 'p': [0.6, 0.4],\n",
        "            'SSLfinal_State': [-1, 0, 1], 'p_ssl': [0.7, 0.2, 0.1],\n",
        "            'has_political_keyword': [0]\n",
        "        },\n",
        "        'cybercrime': {\n",
        "            'having_IP_Address': [1, -1], 'p': [0.3, 0.7],\n",
        "            'SSLfinal_State': [-1, 0, 1], 'p_ssl': [0.5, 0.3, 0.2],\n",
        "            'has_political_keyword': [0]\n",
        "        },\n",
        "        'hacktivist': {\n",
        "            'having_IP_Address': [1, -1], 'p': [0.4, 0.6],\n",
        "            'SSLfinal_State': [-1, 0, 1], 'p_ssl': [0.6, 0.3, 0.1],\n",
        "            'has_political_keyword': [1]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    benign_profile = {\n",
        "        'having_IP_Address': [1, -1], 'p': [0.05, 0.95],\n",
        "        'SSLfinal_State': [-1, 0, 1], 'p_ssl': [0.05, 0.15, 0.8],\n",
        "        'has_political_keyword': [0]\n",
        "    }\n",
        "\n",
        "    def create_samples(profile, count, label):\n",
        "        data = {\n",
        "            'having_IP_Address': np.random.choice(profile['having_IP_Address'], count, p=profile['p']),\n",
        "            'URL_Length': np.random.choice([1, 0, -1], count),\n",
        "            'Shortining_Service': np.random.choice([1, -1], count),\n",
        "            'having_At_Symbol': np.random.choice([1, -1], count),\n",
        "            'double_slash_redirecting': np.random.choice([1, -1], count),\n",
        "            'Prefix_Suffix': np.random.choice([1, -1], count),\n",
        "            'having_Sub_Domain': np.random.choice([1, 0, -1], count),\n",
        "            'SSLfinal_State': np.random.choice(profile['SSLfinal_State'], count, p=profile['p_ssl']),\n",
        "            'URL_of_Anchor': np.random.choice([-1, 0, 1], count),\n",
        "            'Links_in_tags': np.random.choice([-1, 0, 1], count),\n",
        "            'SFH': np.random.choice([-1, 0, 1], count),\n",
        "            'Abnormal_URL': np.random.choice([1, -1], count),\n",
        "            'has_political_keyword': np.random.choice(profile['has_political_keyword'], count)\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        df['actor_profile'] = label\n",
        "        return df\n",
        "\n",
        "    dfs = []\n",
        "    for profile_name, profile_data in profiles.items():\n",
        "        dfs.append(create_samples(profile_data, num_samples // 4, profile_name))\n",
        "    dfs.append(create_samples(benign_profile, num_samples // 4, 'benign'))\n",
        "\n",
        "    final_df = pd.concat(dfs, ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "    filename = f\"synthetic_threat_data_{timestamp}.csv\"\n",
        "    final_df.to_csv(filename, index=False)\n",
        "    print(f\"Synthetic dataset saved to '{filename}'\")\n",
        "    print(\"Sample counts per actor profile:\")\n",
        "    print(final_df['actor_profile'].value_counts())\n",
        "\n",
        "    return final_df\n",
        "\n",
        "def train_models():\n",
        "    df = generate_synthetic_data()\n",
        "\n",
        "    print(\"Training classification model...\")\n",
        "    clf_exp = ClassificationExperiment()\n",
        "    clf_exp.setup(data=df, target='actor_profile', session_id=42)\n",
        "    clf_model = clf_exp.create_model('rf')\n",
        "    clf_exp.save_model(clf_model, 'phishing_url_detector')\n",
        "    print(\"Classification model saved as 'phishing_url_detector.pkl'\")\n",
        "\n",
        "    print(\"Training clustering model...\")\n",
        "    clustering_df = df[df['actor_profile'] != 'benign'].drop(columns=['actor_profile'])\n",
        "    clust_exp = ClusteringExperiment()\n",
        "    clust_exp.setup(data=clustering_df, session_id=42)\n",
        "    clust_model = clust_exp.create_model('kmeans', num_clusters=3)\n",
        "    clust_exp.save_model(clust_model, 'threat_actor_profiler')\n",
        "    print(\"Clustering model saved as 'threat_actor_profiler.pkl'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_models()\n",
        "\"\"\"\n",
        "\n",
        "with open(\"train_model.py\", \"w\") as f:\n",
        "    f.write(train_model_code)\n"
      ],
      "metadata": {
        "id": "pm9uWQu52OyB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Execute training script to generate synthetic data and save classification/clustering models\n",
        "!/usr/local/bin/python3.10 train_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5FkPxfF4dkY",
        "outputId": "151c8225-6376-4307-c433-c4a2e71d299d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic dataset...\n",
            "Synthetic dataset saved to 'synthetic_threat_data_20250823_0354.csv'\n",
            "Sample counts per actor profile:\n",
            "actor_profile\n",
            "state_sponsored    150\n",
            "benign             150\n",
            "hacktivist         150\n",
            "cybercrime         150\n",
            "Name: count, dtype: int64\n",
            "Training classification model...\n",
            "                    Description                                              Value\n",
            "0                    Session id                                                 42\n",
            "1                        Target                                      actor_profile\n",
            "2                   Target type                                         Multiclass\n",
            "3                Target mapping  benign: 0, cybercrime: 1, hacktivist: 2, state...\n",
            "4           Original data shape                                          (600, 14)\n",
            "5        Transformed data shape                                          (600, 14)\n",
            "6   Transformed train set shape                                          (420, 14)\n",
            "7    Transformed test set shape                                          (180, 14)\n",
            "8              Numeric features                                                 13\n",
            "9                    Preprocess                                               True\n",
            "10              Imputation type                                             simple\n",
            "11           Numeric imputation                                               mean\n",
            "12       Categorical imputation                                               mode\n",
            "13               Fold Generator                                    StratifiedKFold\n",
            "14                  Fold Number                                                 10\n",
            "15                     CPU Jobs                                                 -1\n",
            "16                      Use GPU                                              False\n",
            "17               Log Experiment                                              False\n",
            "18              Experiment Name                                   clf-default-name\n",
            "19                          USI                                               c78f\n",
            "      Accuracy  ...     MCC\n",
            "Fold            ...        \n",
            "0       0.7381  ...  0.6532\n",
            "1       0.6667  ...  0.5568\n",
            "2       0.6905  ...  0.5969\n",
            "3       0.6190  ...  0.5047\n",
            "4       0.6429  ...  0.5239\n",
            "5       0.5714  ...  0.4287\n",
            "6       0.6905  ...  0.5874\n",
            "7       0.6905  ...  0.5880\n",
            "8       0.6905  ...  0.5969\n",
            "9       0.6190  ...  0.4951\n",
            "Mean    0.6619  ...  0.5532\n",
            "Std     0.0462  ...  0.0619\n",
            "\n",
            "[12 rows x 7 columns]\n",
            "Transformation Pipeline and Model Successfully Saved\n",
            "Classification model saved as 'phishing_url_detector.pkl'\n",
            "Training clustering model...\n",
            "               Description                 Value\n",
            "0               Session id                    42\n",
            "1      Original data shape             (450, 13)\n",
            "2   Transformed data shape             (450, 13)\n",
            "3         Numeric features                    13\n",
            "4               Preprocess                  True\n",
            "5          Imputation type                simple\n",
            "6       Numeric imputation                  mean\n",
            "7   Categorical imputation                  mode\n",
            "8                 CPU Jobs                    -1\n",
            "9                  Use GPU                 False\n",
            "10          Log Experiment                 False\n",
            "11         Experiment Name  cluster-default-name\n",
            "12                     USI                  96cd\n",
            "   Silhouette  ...  Completeness\n",
            "0      0.0848  ...             0\n",
            "\n",
            "[1 rows x 6 columns]\n",
            "Transformation Pipeline and Model Successfully Saved\n",
            "Clustering model saved as 'threat_actor_profiler.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Write the full script to app.py\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from pycaret.classification import load_model as load_classification_model, predict_model as predict_classification\n",
        "from pycaret.clustering import load_model as load_clustering_model, predict_model as predict_clustering\n",
        "import os\n",
        "\n",
        "# Step 1: Configure Streamlit Page\n",
        "st.set_page_config(page_title=\"GenAI-Powered Phishing SOAR\", layout=\"wide\")\n",
        "\n",
        "# Step 2: Load Models and Optional Feature Plot\n",
        "@st.cache_resource\n",
        "def load_assets():\n",
        "    clf_path = 'models/phishing_url_detector'\n",
        "    cluster_path = 'models/threat_actor_profiler'\n",
        "    plot_path = 'models/feature_importance.png'\n",
        "\n",
        "    clf_model = load_classification_model(clf_path) if os.path.exists(clf_path + '.pkl') else None\n",
        "    cluster_model = load_clustering_model(cluster_path) if os.path.exists(cluster_path + '.pkl') else None\n",
        "    plot = plot_path if os.path.exists(plot_path) else None\n",
        "\n",
        "    return clf_model, plot, cluster_model\n",
        "\n",
        "model, feature_plot, cluster_model = load_assets()\n",
        "\n",
        "if not model:\n",
        "    st.error(\"Classification model not found. Please run training first or check logs.\")\n",
        "    st.stop()\n",
        "\n",
        "# Step 3: Collect User Inputs via Sidebar\n",
        "with st.sidebar:\n",
        "    st.title(\"URL Feature Input\")\n",
        "    st.write(\"Describe the characteristics of a suspicious URL below.\")\n",
        "\n",
        "    test_case = st.selectbox(\"Load a Test Case\", options=[\"None\", \"Benign\", \"Cybercrime\", \"State-Sponsored\", \"Hacktivist\"])\n",
        "\n",
        "    preset_inputs = {\n",
        "        \"Benign\": {\n",
        "            'url_length': 'Normal', 'ssl_state': 'Trusted', 'sub_domain': 'One',\n",
        "            'prefix_suffix': False, 'has_ip': False, 'short_service': False,\n",
        "            'at_symbol': False, 'double_slash': False, 'anchor': 'Trusted',\n",
        "            'links_in_tags': 'Trusted', 'sfh': 'Trusted', 'abnormal_url': False,\n",
        "            'political_keyword': False\n",
        "        },\n",
        "        \"Cybercrime\": {\n",
        "            'url_length': 'Long', 'ssl_state': 'None', 'sub_domain': 'Many',\n",
        "            'prefix_suffix': True, 'has_ip': True, 'short_service': True,\n",
        "            'at_symbol': True, 'double_slash': True, 'anchor': 'Suspicious',\n",
        "            'links_in_tags': 'Suspicious', 'sfh': 'Suspicious', 'abnormal_url': True,\n",
        "            'political_keyword': False\n",
        "        },\n",
        "        \"State-Sponsored\": {\n",
        "            'url_length': 'Normal', 'ssl_state': 'Trusted', 'sub_domain': 'One',\n",
        "            'prefix_suffix': True, 'has_ip': False, 'short_service': False,\n",
        "            'at_symbol': False, 'double_slash': False, 'anchor': 'Neutral',\n",
        "            'links_in_tags': 'Neutral', 'sfh': 'Neutral', 'abnormal_url': False,\n",
        "            'political_keyword': False\n",
        "        },\n",
        "        \"Hacktivist\": {\n",
        "            'url_length': 'Long', 'ssl_state': 'Suspicious', 'sub_domain': 'Many',\n",
        "            'prefix_suffix': True, 'has_ip': True, 'short_service': False,\n",
        "            'at_symbol': True, 'double_slash': True, 'anchor': 'Suspicious',\n",
        "            'links_in_tags': 'Neutral', 'sfh': 'Suspicious', 'abnormal_url': True,\n",
        "            'political_keyword': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if test_case != \"None\":\n",
        "        form_values = preset_inputs[test_case]\n",
        "    else:\n",
        "        form_values = {\n",
        "            'url_length': st.select_slider(\"URL Length\", options=['Short', 'Normal', 'Long']),\n",
        "            'ssl_state': st.select_slider(\"SSL Certificate Status\", options=['Trusted', 'Suspicious', 'None']),\n",
        "            'sub_domain': st.select_slider(\"Sub-domain Complexity\", options=['None', 'One', 'Many']),\n",
        "            'prefix_suffix': st.checkbox(\"URL has a Prefix/Suffix (e.g., '-')\"),\n",
        "            'has_ip': st.checkbox(\"URL uses an IP Address\"),\n",
        "            'short_service': st.checkbox(\"Is it a shortened URL\"),\n",
        "            'at_symbol': st.checkbox(\"URL contains '@' symbol\"),\n",
        "            'double_slash': st.checkbox(\"URL contains '//' after protocol\"),\n",
        "            'anchor': st.select_slider(\"Anchor Tag Behavior\", options=['Trusted', 'Neutral', 'Suspicious']),\n",
        "            'links_in_tags': st.select_slider(\"Links in Tags\", options=['Trusted', 'Neutral', 'Suspicious']),\n",
        "            'sfh': st.select_slider(\"Server Form Handler (SFH)\", options=['Trusted', 'Neutral', 'Suspicious']),\n",
        "            'abnormal_url': st.checkbox(\"URL is Abnormal (e.g., doesn't match domain)\"),\n",
        "            'political_keyword': st.checkbox(\"Contains Political Keywords\")\n",
        "        }\n",
        "\n",
        "# Step 4: Display Feature Importance Plot\n",
        "if feature_plot:\n",
        "    st.image(feature_plot, caption=\"Feature Importance\", use_column_width=True)\n",
        "\n",
        "# Step 5: Run Predictions\n",
        "if st.button(\"Run Attribution\"):\n",
        "    input_df = pd.DataFrame([form_values])\n",
        "\n",
        "    # Classification\n",
        "    clf_result = predict_classification(model, data=input_df)\n",
        "    predicted_label = clf_result.loc[0, 'Label']\n",
        "    prediction_score = clf_result.loc[0, 'Score']\n",
        "\n",
        "    st.subheader(\" Phishing Classification Result\")\n",
        "    st.markdown(f\"- **Predicted Label:** `{predicted_label}`\")\n",
        "    st.markdown(f\"- **Confidence Score:** `{prediction_score:.2f}`\")\n",
        "\n",
        "    # Clustering\n",
        "    if cluster_model:\n",
        "        cluster_result = predict_clustering(cluster_model, data=input_df)\n",
        "        cluster_label = cluster_result.loc[0, 'Cluster']\n",
        "\n",
        "        st.subheader(\" Threat Actor Attribution\")\n",
        "        st.markdown(f\"- **Assigned Cluster:** `{cluster_label}`\")\n",
        "\n",
        "        cluster_map = {\n",
        "            0: \"Benign\",\n",
        "            1: \"Cybercrime\",\n",
        "            2: \"State-Sponsored\",\n",
        "            3: \"Hacktivist\"\n",
        "        }\n",
        "        actor_type = cluster_map.get(cluster_label, \"Unknown\")\n",
        "        st.markdown(f\"- **Likely Actor Type:** `{actor_type}`\")\n",
        "\n",
        "        st.info(\"This attribution is based on clustering of behavioral URL features. Please validate against known threat actor profiles and campaign metadata.\")\n",
        "\n",
        "    # Step 6: Optional Export\n",
        "    if st.checkbox(\"Save Prediction to CSV\"):\n",
        "        output_df = pd.DataFrame({\n",
        "            \"Predicted Label\": [predicted_label],\n",
        "            \"Confidence Score\": [prediction_score],\n",
        "            \"Assigned Cluster\": [cluster_label],\n",
        "            \"Actor Type\": [actor_type]\n",
        "        })\n",
        "        timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"outputs/prediction_{timestamp}.csv\"\n",
        "        output_df.to_csv(filename, index=False)\n",
        "        st.success(f\"Prediction saved as {filename}\")\n",
        "\n",
        "    # Step 7: Justification Block\n",
        "    with st.expander(\" Attribution Justification\"):\n",
        "        st.markdown(\"\"\"\n",
        "        The classification model predicts phishing likelihood based on behavioral URL features.\n",
        "        The clustering model assigns threat actor types using unsupervised profiling.\n",
        "\n",
        "        - **Benign**: Low-risk, trusted indicators\n",
        "        - **Cybercrime**: High-risk, evasive patterns\n",
        "        - **State-Sponsored**: Neutral but strategic indicators\n",
        "        - **Hacktivist**: Politically charged and disruptive traits\n",
        "\n",
        "        Please validate results against campaign metadata and known actor profiles.\n",
        "        \"\"\")\n",
        "'''\n",
        "\n",
        "# Step 8: Write the full Streamlit interface to app.py for later deployment or local execution\n",
        "# This file wraps the trained models into an interactive attribution tool using PyCaret and Streamlit.\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\" Streamlit app saved successfully as 'app.py'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmFT99yiBJcl",
        "outputId": "0d656452-9d8c-428f-f548-8b4d9d0a7af2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Streamlit app saved successfully as 'app.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Verify that trained model files were successfully saved\n",
        "# This loop lists all .pkl files in the current working directory, confirming that both\n",
        "# 'phishing_url_detector.pkl' and 'threat_actor_profiler.pkl' exist for use in the Streamlit app.\n",
        "import os\n",
        "\n",
        "print(\"Files in current directory:\")\n",
        "for f in os.listdir():\n",
        "    if f.endswith('.pkl'):\n",
        "        print(\" \", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN_ZzFV_BrV_",
        "outputId": "e1639d64-659b-4eb7-ae2d-e3fb06ec0f93"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in current directory:\n",
            "  phishing_url_detector.pkl\n",
            "  threat_actor_profiler.pkl\n"
          ]
        }
      ]
    }
  ]
}